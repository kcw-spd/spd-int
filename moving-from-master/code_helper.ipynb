{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain e2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import E2BDataAnalysisTool\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifacts are charts created by matplotlib when `plt.show()` is called\n",
    "def save_artifact(artifact):\n",
    "    print(\"New matplotlib chart generated:\", artifact.name)\n",
    "    # Download the artifact as `bytes` and leave it up to the user to display them (on frontend, for example)\n",
    "    file = artifact.download()\n",
    "    basename = os.path.basename(artifact.name)\n",
    "\n",
    "    # Save the chart to the `charts` directory\n",
    "    with open(f\"./charts/{basename}\", \"wb\") as f:\n",
    "        f.write(file)\n",
    "\n",
    "\n",
    "e2b_data_analysis_tool = E2BDataAnalysisTool(\n",
    "    # Pass environment variables to the sandbox\n",
    "    env_vars={\"MY_SECRET\": \"secret_value\"},\n",
    "    on_stdout=lambda stdout: print(\"stdout:\", stdout),\n",
    "    on_stderr=lambda stderr: print(\"stderr:\", stderr),\n",
    "    on_artifact=save_artifact,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='x_unique_cars_final_types_x_3.csv' remote_path='/home/user/x_unique_cars_final_types_x_3.csv' description='Our master dataset of cars, this includes all makes models and types.'\n",
      "name='refactored_return_top3.py' remote_path='/home/user/refactored_return_top3.py' description='The current python script that we are working on, we are trying to determine if it is working properly.'\n"
     ]
    }
   ],
   "source": [
    "with open(\"x_unique_cars_final_types_x_3.csv\") as f:\n",
    "    remote_path = e2b_data_analysis_tool.upload_file(\n",
    "        file=f,\n",
    "        description=\"Our master dataset of cars, this includes all makes models and types.\",\n",
    "    )\n",
    "    print(remote_path)\n",
    "with open(\"refactored_return_top3.py\") as f:\n",
    "    remote_path = e2b_data_analysis_tool.upload_file(\n",
    "        file=f,\n",
    "        description=\"The current python script that we are working on, we are trying to determine if it is working properly.\",\n",
    "    )\n",
    "    print(remote_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kylew\\Source Path Digital\\Code\\e2b-cookbook\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "tools = [e2b_data_analysis_tool.as_tool()]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stdout: Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.1.4)\n",
      "stdout: Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "stdout: Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "stdout: Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "stdout: Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "stdout: Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "stderr: \n",
      "stderr: [notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "stderr: [notice] To update, run: pip install --upgrade pip\n",
      "stdout: Collecting mysql-connector-python\n",
      "stdout:   Obtaining dependency information for mysql-connector-python from https://files.pythonhosted.org/packages/c9/6a/df8325eb997944357f5f24e55900f24c4f82ab980ac7f0b013ef87c996e7/mysql_connector_python-8.2.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata\n",
      "stdout:   Downloading mysql_connector_python-8.2.0-cp311-cp311-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "stdout: Collecting protobuf<=4.21.12,>=4.21.1 (from mysql-connector-python)\n",
      "stdout:   Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
      "stdout:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 3.0 MB/s eta 0:00:00\n",
      "stdout: Downloading mysql_connector_python-8.2.0-cp311-cp311-manylinux_2_17_x86_64.whl (31.6 MB)\n",
      "stdout:    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.6/31.6 MB 10.4 MB/s eta 0:00:00\n",
      "stdout: Installing collected packages: protobuf, mysql-connector-python\n",
      "stdout: Successfully installed mysql-connector-python-8.2.0 protobuf-4.21.12\n",
      "stderr: \n",
      "stderr: [notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "stderr: [notice] To update, run: pip install --upgrade pip\n",
      "stdout: Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (1.26.2)\n",
      "stderr: \n",
      "stderr: [notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "stderr: [notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "e2b_data_analysis_tool.install_python_packages(\"pandas\")\n",
    "e2b_data_analysis_tool.install_python_packages(\"mysql-connector-python\")\n",
    "e2b_data_analysis_tool.install_python_packages(\"numpy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `e2b_data_analysis` with `{'python_code': \"with open('/home/user/refactored_return_top3.py', 'r') as file:\\n    data = file.read()\\nprint(data)\"}`\n",
      "\n",
      "\n",
      "\u001b[0mstdout: from pprint import pprint\n",
      "stdout: import pandas as pd\n",
      "stdout: import random\n",
      "stdout: import mysql.connector\n",
      "stdout: import os\n",
      "stdout: from dotenv import load_dotenv\n",
      "stdout: from random import choices\n",
      "stdout: import numpy as np\n",
      "stdout: \n",
      "stdout: load_dotenv()\n",
      "stdout: print(\"Environment variables loaded.\")\n",
      "stdout: \n",
      "stdout: # Load the master vehicle list into a Pandas DataFrame\n",
      "stdout: vehicle_list_df = pd.read_csv(r'C:\\Users\\kylew\\Source Path Digital\\Code\\x_unique_cars_final_types_x_3.csv')\n",
      "stdout: print(\"Vehicle list DataFrame loaded.\")\n",
      "stdout: \n",
      "stdout: # Convert the vehicle list DataFrame into a dictionary for easy lookup\n",
      "stdout: vehicle_type_map = vehicle_list_df.set_index(['MAKE', 'MODEL']).to_dict('index')\n",
      "stdout: print(\"Vehicle type map created.\")\n",
      "stdout: \n",
      "stdout: load_dotenv()\n",
      "stdout: \n",
      "stdout: # Load the master vehicle list into a Pandas DataFrame\n",
      "stdout: vehicle_list_df = pd.read_csv(r'C:\\Users\\kylew\\Source Path Digital\\Code\\x_unique_cars_final_types_x_3.csv')\n",
      "stdout: \n",
      "stdout: # Convert the vehicle list DataFrame into a dictionary for easy lookup\n",
      "stdout: vehicle_type_map = vehicle_list_df.set_index(['MAKE', 'MODEL']).to_dict('index')\n",
      "stdout: \n",
      "stdout: # These represent an Auto Owner's loyalty score for each brand\n",
      "stdout: loyalty_scores = {\n",
      "stdout:     'ACURA' : 0.5,\n",
      "stdout:     'ALFA ROMEO' : 0.421,\n",
      "stdout:     'AM GENERAL' : 0,\n",
      "stdout:     'AMC' : 0,\n",
      "stdout:     'AMERICAN MOTORS (AMC)' : 0,\n",
      "stdout:     'ASTON MARTIN' : 0.389,\n",
      "stdout:     'AUDI' : 0.388,\n",
      "stdout:     'BENTLEY' : 0.607,\n",
      "stdout:     'BMW' : 0.644,\n",
      "stdout:     'BUICK' : 0.485,\n",
      "stdout:     'CADILLAC' : 0.478,\n",
      "stdout:     'CHEVROLET' : 0.596,\n",
      "stdout:     'CHRYSLER' : 0.294,\n",
      "stdout:     'DAEWOO' : 0,\n",
      "stdout:     'DAIHATSU' : 0,\n",
      "stdout:     'DATSUN' : 0,\n",
      "stdout:     'DELOREAN' : 0,\n",
      "stdout:     'DODGE' : 0.248,\n",
      "stdout:     'EAGLE' : 0,\n",
      "stdout:     'FERRARI' : 0.587,\n",
      "stdout:     'FIAT' : 0.024,\n",
      "stdout:     'FISKER' : 0,\n",
      "stdout:     'FORD' : 0.734,\n",
      "stdout:     'GENESIS' : 0.575,\n",
      "stdout:     'GEO' : 0,\n",
      "stdout:     'GMC' : 0.502,\n",
      "stdout:     'HONDA' : 0.621,\n",
      "stdout:     'HUMMER' : 0,\n",
      "stdout:     'HYUNDAI' : 0.64,\n",
      "stdout:     'INFINITI' : 0.379,\n",
      "stdout:     'ISUZU' : 0,\n",
      "stdout:     'JAGUAR' : 0.125,\n",
      "stdout:     'JEEP' : 0.527,\n",
      "stdout:     'KARMA' : 0.444,\n",
      "stdout:     'KIA' : 0.648,\n",
      "stdout:     'LAMBORGHINI' : 0.413,\n",
      "stdout:     'LAND ROVER' : 0.376,\n",
      "stdout:     'LEXUS' : 0.553,\n",
      "stdout:     'LINCOLN' : 0.571,\n",
      "stdout:     'LOTUS' : 0,\n",
      "stdout:     'MASERATI' : 0.488,\n",
      "stdout:     'MAYBACH' : 0,\n",
      "stdout:     'MAZDA' : 0,\n",
      "stdout:     'MCLAREN' : 0.455,\n",
      "stdout:     'MERCEDES-BENZ' : 0.543,\n",
      "stdout:     'MERCURY' : 0,\n",
      "stdout:     'MERKUR' : 0,\n",
      "stdout:     'MINI' : 0.409,\n",
      "stdout:     'MITSUBISHI' : 0.533,\n",
      "stdout:     'NISSAN' : 0.609,\n",
      "stdout:     'OLDSMOBILE' : 0,\n",
      "stdout:     'PEUGEOT' : 0,\n",
      "stdout:     'PININFARINA' : 0,\n",
      "stdout:     'PLYMOUTH' : 0,\n",
      "stdout:     'POLESTAR' : 0.412,\n",
      "stdout:     'PONTIAC' : 0,\n",
      "stdout:     'PORSCHE' : 0.529,\n",
      "stdout:     'RAM' : 0.6,\n",
      "stdout:     'RENAULT' : 0,\n",
      "stdout:     'ROLLS-ROYCE' : 0.52,\n",
      "stdout:     'SAAB' : 0,\n",
      "stdout:     'SATURN' : 0,\n",
      "stdout:     'SCION' : 0,\n",
      "stdout:     'SMART' : 0,\n",
      "stdout:     'SUBARU' : 0.624,\n",
      "stdout:     'SUZUKI' : 0,\n",
      "stdout:     'TESLA' : 0.796,\n",
      "stdout:     'TOYOTA' : 0.637,\n",
      "stdout:     'VOLKSWAGEN' : 0.563,\n",
      "stdout:     'VOLVO' : 0.535,\n",
      "stdout:     'WAGONEER' : 0\n",
      "stdout: }\n",
      "stdout: \n",
      "stdout: # This is how a person's car is defined as Luxury \n",
      "stdout: luxury_brands = ['ACURA', 'ALFA ROMEO', 'ASTON MARTIN', 'AUDI', 'BENTLEY', 'BUICK', 'BMW', 'CADILLAC', 'FERRARI', 'FIAT', 'FISKER', 'GENESIS', 'HUMMER', 'INFINITI', 'JAGUAR', 'KARMA', 'LAMBORGHINI', 'LAND ROVER', 'LEXUS', 'LINCOLN', 'LOTUS', 'MASERATI', 'MAYBACH', 'MCLAREN', 'MERCEDES-BENZ', 'MINI', 'PININFARINA', 'POLESTAR', 'PORSCHE', 'ROLLS-ROYCE', 'SAAB', 'TESLA', 'VOLVO']\n",
      "stdout: \n",
      "stdout: # Define spacious vehicle types\n",
      "stdout: spacious_vehicle_types = {'SUV', 'MID_SIZE_SUV', 'FULL_SIZE_SUV', 'MINIVAN'}\n",
      "stdout: \n",
      "stdout: # Define luxury vehicle types\n",
      "stdout: luxury_vehicle_types = {'SEDAN', 'SPORTS_CAR', 'ELECTRIC_VEHICLE', 'FULL_SIZE_SUV'}\n",
      "stdout: \n",
      "stdout: \n",
      "stdout: # Assuming a mapping of IncomeKey from A (lowest) to higher (more likely to afford luxury)\n",
      "stdout: income_key_mapping = {key: index + 1 for index, key in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"U\"])}\n",
      "stdout: \n",
      "stdout: # Function to assign a random vehicle\n",
      "stdout: def assign_random_vehicle(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\n",
      "stdout:     weights = []\n",
      "stdout:     for _, row in vehicle_list_df.iterrows():\n",
      "stdout:         weight = 1.0\n",
      "stdout: \n",
      "stdout:         # Adjust weight based on loyalty score\n",
      "stdout:         if row['MAKE'] == owner_make:\n",
      "stdout:             weight += owner_loyalty_score\n",
      "stdout: \n",
      "stdout:         # Adjust weight for luxury owners\n",
      "stdout:         if is_luxury_owner and row['MAKE'] in luxury_brands:\n",
      "stdout:             weight *= 2\n",
      "stdout: \n",
      "stdout:         # Adjust weight for owners with children preferring spacious vehicles\n",
      "stdout:         if presence_of_children == 'Yes' and any(row[type_col] == 1 for type_col in spacious_vehicle_types):\n",
      "stdout:             weight *= 1.5\n",
      "stdout: \n",
      "stdout:         # Adjust weight based on income key (higher income, higher weight for luxury vehicles)\n",
      "stdout:         if row['MAKE'] in luxury_brands and income_key >= 15:  # Assuming income keys 15 and above indicate higher income\n",
      "stdout:             weight *= 1.5\n",
      "stdout: \n",
      "stdout:         weights.append(weight)\n",
      "stdout: \n",
      "stdout:     # Normalize the weights\n",
      "stdout:     total_weight = sum(weights)\n",
      "stdout:     normalized_weights = [w / total_weight for w in weights]\n",
      "stdout: \n",
      "stdout:     # Choose the top 3 vehicles based on the weights\n",
      "stdout:     chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=normalized_weights)\n",
      "stdout:     recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\n",
      "stdout:     return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records')\n",
      "stdout: # Function to assign the top 3 most likely vehicles\n",
      "stdout: \n",
      "stdout: def perform_sanity_checks(recommended_vehicles, debug_info, vehicle_list_df, luxury_brands, owner_luxury):\n",
      "stdout:     errors = []  # To store any errors found during sanity checks\n",
      "stdout: \n",
      "stdout:     # Check if the recommended vehicles' types match one of the types in the dataframe\n",
      "stdout:     for rec in recommended_vehicles:\n",
      "stdout:         make = rec['MAKE']\n",
      "stdout:         model = rec['MODEL']\n",
      "stdout:         has_valid_type = any(vehicle_list_df[(vehicle_list_df['MAKE'] == make) & (vehicle_list_df['MODEL'] == model)][col] == 1 for col in vehicle_list_df.columns if col.startswith('TYPE_'))\n",
      "stdout:         if not has_valid_type:\n",
      "stdout:             errors.append(f\"Inappropriate or undefined vehicle type for {make} {model}.\")\n",
      "stdout: \n",
      "stdout:     # If owner does not own a luxury brand, it's okay to recommend non-luxury brands\n",
      "stdout:     if owner_luxury and not all(rec['MAKE'] in luxury_brands for rec in recommended_vehicles):\n",
      "stdout:         errors.append(\"Non-luxury brands are being recommended to a luxury brand owner.\")\n",
      "stdout: \n",
      "stdout:     # Check if the weights are correctly adjusted and normalized\n",
      "stdout:     total_weight = sum(item['Final Weight'] for item in debug_info)\n",
      "stdout:     expected_total_weight = len(debug_info)  # Should be equal to the number of rows iterated over\n",
      "stdout:     if not np.isclose(total_weight, expected_total_weight, rtol=1e-03):\n",
      "stdout:         errors.append(f\"Total weight mismatch. Expected ~{expected_total_weight}, got {total_weight}.\")\n",
      "stdout: \n",
      "stdout:     if errors:\n",
      "stdout:         print(\"Sanity checks failed with the following errors:\")\n",
      "stdout:         for error in errors:\n",
      "stdout:             print(f\" - {error}\")\n",
      "stdout:     else:\n",
      "stdout:         print(\"Sanity checks passed.\")\n",
      "stdout: \n",
      "stdout: \n",
      "stdout: \"\"\"def assign_top_vehicles(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\n",
      "stdout:     weights = []\n",
      "stdout:     debug_info = []  # To store debug information\n",
      "stdout: \n",
      "stdout:     print(\"\\n### Debugging Weights Calculation Start ###\")  # Start of debugging block\n",
      "stdout: \n",
      "stdout:     for index, row in vehicle_list_df.iterrows():\n",
      "stdout:         weight = 1.0\n",
      "stdout:         debug_details = {'Index': index, 'Make': row['MAKE'], 'Model': row['MODEL'], 'Initial Weight': weight}\n",
      "stdout: \n",
      "stdout:         print(f\"Initial weight for {row['MAKE']} {row['MODEL']}: {weight}\")  # Initial weight\n",
      "stdout: \n",
      "stdout:         # Adjust weight based on loyalty score\n",
      "stdout:         if row['MAKE'] == owner_make:\n",
      "stdout:             loyalty_bonus = owner_loyalty_score\n",
      "stdout:             weight *= (1 + loyalty_bonus)  # Increase the likelihood for the same make\n",
      "stdout:             debug_details['Loyalty Weight Adjustment'] = f\"+{loyalty_bonus}\"\n",
      "stdout: \n",
      "stdout:         # Adjust weight for luxury owners\n",
      "stdout:         if is_luxury_owner and row['MAKE'] in luxury_brands:\n",
      "stdout:             weight *= 2\n",
      "stdout:             debug_details['Luxury Owner Weight Multiplier'] = 2\n",
      "stdout:             print(\"Luxury owner: weight doubled\")  # Luxury owner adjustment\n",
      "stdout: \n",
      "stdout:         # Adjust weight for owners with children preferring spacious vehicles\n",
      "stdout:         if presence_of_children == 'Yes' and any(row[type_col] == 1 for type_col in spacious_vehicle_types):\n",
      "stdout:             weight *= 1.5\n",
      "stdout:             debug_details['Children Weight Multiplier'] = 1.5\n",
      "stdout:             print(\"Presence of children: weight *= 1.5\")  # Children presence adjustment\n",
      "stdout: \n",
      "stdout:         # Adjust weight based on income key\n",
      "stdout:         if row['MAKE'] in luxury_brands and income_key >= 15:  # Assuming income keys 15 and above indicate higher income\n",
      "stdout:             weight *= 1.5\n",
      "stdout:             debug_details['Income Weight Multiplier'] = 1.5\n",
      "stdout:             print(\"Higher income level: weight *= 1.5\")  # Income level adjustment\n",
      "stdout: \n",
      "stdout:         weights.append(weight)\n",
      "stdout:         debug_details['Final Weight'] = weight\n",
      "stdout:         debug_info.append(debug_details)\n",
      "stdout:         print(f\"Final weight for {row['MAKE']} {row['MODEL']}: {weight}\")  # Final weight\n",
      "stdout: \n",
      "stdout:     print(\"Total weight before normalization:\", sum(weights))  # Total weight before normalization\n",
      "stdout: \n",
      "stdout:     # Normalize the weights\n",
      "stdout:     total_weight = sum(weights)\n",
      "stdout:     normalized_weights = [w / total_weight for w in weights]\n",
      "stdout: \n",
      "stdout:     print(\"Normalized weights:\", normalized_weights)  # Normalized weights\n",
      "stdout: \n",
      "stdout:     # Choose the top 3 vehicles based on the weights\n",
      "stdout:     chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=normalized_weights)\n",
      "stdout:     recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\n",
      "stdout: \n",
      "stdout:     print(\"\\n### Debugging Weights Calculation End ###\")  # End of debugging block\n",
      "stdout: \n",
      "stdout:     # Debug print\n",
      "stdout:     pprint(\"Vehicle Selection Debug Information:\")\n",
      "stdout:     for info in debug_info:\n",
      "stdout:         if info['Index'] in chosen_indices:\n",
      "stdout:             pprint(info)\n",
      "stdout:     \n",
      "stdout:     # Return both recommended vehicles and debug information\n",
      "stdout:     return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records'), debug_info\n",
      "stdout: \n",
      "stdout: \"\"\"\n",
      "stdout: def assign_top_vehicles(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\n",
      "stdout:     # Initialize weights as 1 for all vehicles\n",
      "stdout:     weights = np.ones(len(vehicle_list_df))\n",
      "stdout:     \n",
      "stdout:     # Adjust weight based on loyalty score\n",
      "stdout:     loyalty_weight_mask = (vehicle_list_df['MAKE'] == owner_make)\n",
      "stdout:     weights[loyalty_weight_mask] += owner_loyalty_score\n",
      "stdout:     \n",
      "stdout:     # Adjust weight for luxury owners\n",
      "stdout:     if is_luxury_owner:\n",
      "stdout:         luxury_mask = vehicle_list_df['MAKE'].isin(luxury_brands)\n",
      "stdout:         weights[luxury_mask] *= 2\n",
      "stdout:     \n",
      "stdout:     # Adjust weight for owners with children preferring spacious vehicles\n",
      "stdout:     if presence_of_children == 'Yes':\n",
      "stdout:         for vehicle_type in spacious_vehicle_types:\n",
      "stdout:             spacious_mask = (vehicle_list_df[vehicle_type] == 1)\n",
      "stdout:             weights[spacious_mask] *= 1.5\n",
      "stdout:     \n",
      "stdout:     # Adjust weight based on income key\n",
      "stdout:     if income_key >= 15:  # Assuming income keys 15 and above indicate higher income\n",
      "stdout:         higher_income_luxury_mask = vehicle_list_df['MAKE'].isin(luxury_brands)\n",
      "stdout:         weights[higher_income_luxury_mask] *= 1.5\n",
      "stdout:     \n",
      "stdout:     # Normalize the weights\n",
      "stdout:     weights /= weights.sum()\n",
      "stdout:     \n",
      "stdout:     # Choose the top 3 vehicles based on the weights\n",
      "stdout:     chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=weights)\n",
      "stdout:     recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\n",
      "stdout:     \n",
      "stdout:     return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records')\n",
      "stdout: \n",
      "stdout: db_config = {\n",
      "stdout:     'host': 'localhost',\n",
      "stdout:     'user': 'root',\n",
      "stdout:     'password': 'password1',\n",
      "stdout:     'database': 'db'\n",
      "stdout: }\n",
      "stdout: \n",
      "stdout: def create_db_connection():\n",
      "stdout:     try:\n",
      "stdout:         conn = mysql.connector.connect(**db_config)\n",
      "stdout:         print(\"Database connection established.\")\n",
      "stdout:         return conn\n",
      "stdout:     except mysql.connector.Error as err:\n",
      "stdout:         print(f\"Error: {err}\")\n",
      "stdout:         return None\n",
      "stdout: # Function to insert recommendations into the database\n",
      "stdout: def insert_recommendations(conn, customer_id, recommendations):\n",
      "stdout:     cursor = conn.cursor()\n",
      "stdout:     for rec in recommendations:\n",
      "stdout:         insert_query = (\"INSERT INTO vehicle_recommendations (customer_id, make, model, vehicle_types) \"\n",
      "stdout:                         \"VALUES (%s, %s, %s, %s)\")\n",
      "stdout:         cursor.execute(insert_query, (customer_id, rec['MAKE'], rec['MODEL'], rec['VEHICLE_TYPES']))\n",
      "stdout:     conn.commit()\n",
      "stdout:     cursor.close()\n",
      "stdout: \n",
      "stdout: # Function to fetch data and recommend vehicles\n",
      "stdout: def fetch_data_and_recommend(conn):\n",
      "stdout:     cursor = conn.cursor(dictionary=True)\n",
      "stdout:     query = \"SELECT id, PresenceOfChildren, AutoOwnerMake, IncomeKey FROM inventory_table where InventoryId = 50017786\"\n",
      "stdout:     cursor.execute(query)\n",
      "stdout:     results = cursor.fetchall()\n",
      "stdout:     for record in results:\n",
      "stdout:         owner_make = record['AutoOwnerMake'].upper()\n",
      "stdout:         loyalty_score = loyalty_scores.get(owner_make, 0)\n",
      "stdout:         is_luxury_owner = owner_make in luxury_brands\n",
      "stdout:         presence_of_children = 'Yes' if record['PresenceOfChildren'] == 'Yes' else 'No'\n",
      "stdout:         income_rank = income_key_mapping.get(record['IncomeKey'].upper(), 0)  # Default to 0 if not found\n",
      "stdout: \n",
      "stdout:         owner_luxury = owner_make in luxury_brands\n",
      "stdout:         # top_vehicles, debug_info = assign_top_vehicles(owner_make, loyalty_score, owner_luxury, presence_of_children, income_rank)\n",
      "stdout:         insert_recommendations(conn, record['id'], top_vehicles)\n",
      "stdout:         perform_sanity_checks(top_vehicles, debug_info, vehicle_list_df, luxury_brands, owner_luxury)\n",
      "stdout: \n",
      "stdout:         pprint(f\"Profile: {record}\")\n",
      "stdout:         for vehicle in top_vehicles:\n",
      "stdout:             pprint(f\"Recommendation: {vehicle['MAKE']} {vehicle['MODEL']} ({vehicle['VEHICLE_TYPES']})\")\n",
      "stdout:     \n",
      "stdout:     cursor.close()\n",
      "stdout:     \n",
      "stdout:     \n",
      "stdout: if __name__ == '__main__':\n",
      "stdout:     conn = create_db_connection()\n",
      "stdout:     if conn:\n",
      "stdout:         fetch_data_and_recommend(conn)\n",
      "stdout:         conn.close()\n",
      "stdout:     else:\n",
      "stdout:         print(\"Failed to establish database connection.\")\n",
      "\u001b[36;1m\u001b[1;3m{\"stdout\": \"from pprint import pprint\\nimport pandas as pd\\nimport random\\nimport mysql.connector\\nimport os\\nfrom dotenv import load_dotenv\\nfrom random import choices\\nimport numpy as np\\n\\nload_dotenv()\\nprint(\\\"Environment variables loaded.\\\")\\n\\n# Load the master vehicle list into a Pandas DataFrame\\nvehicle_list_df = pd.read_csv(r'C:\\\\Users\\\\kylew\\\\Source Path Digital\\\\Code\\\\x_unique_cars_final_types_x_3.csv')\\nprint(\\\"Vehicle list DataFrame loaded.\\\")\\n\\n# Convert the vehicle list DataFrame into a dictionary for easy lookup\\nvehicle_type_map = vehicle_list_df.set_index(['MAKE', 'MODEL']).to_dict('index')\\nprint(\\\"Vehicle type map created.\\\")\\n\\nload_dotenv()\\n\\n# Load the master vehicle list into a Pandas DataFrame\\nvehicle_list_df = pd.read_csv(r'C:\\\\Users\\\\kylew\\\\Source Path Digital\\\\Code\\\\x_unique_cars_final_types_x_3.csv')\\n\\n# Convert the vehicle list DataFrame into a dictionary for easy lookup\\nvehicle_type_map = vehicle_list_df.set_index(['MAKE', 'MODEL']).to_dict('index')\\n\\n# These represent an Auto Owner's loyalty score for each brand\\nloyalty_scores = {\\n    'ACURA' : 0.5,\\n    'ALFA ROMEO' : 0.421,\\n    'AM GENERAL' : 0,\\n    'AMC' : 0,\\n    'AMERICAN MOTORS (AMC)' : 0,\\n    'ASTON MARTIN' : 0.389,\\n    'AUDI' : 0.388,\\n    'BENTLEY' : 0.607,\\n    'BMW' : 0.644,\\n    'BUICK' : 0.485,\\n    'CADILLAC' : 0.478,\\n    'CHEVROLET' : 0.596,\\n    'CHRYSLER' : 0.294,\\n    'DAEWOO' : 0,\\n    'DAIHATSU' : 0,\\n    'DATSUN' : 0,\\n    'DELOREAN' : 0,\\n    'DODGE' : 0.248,\\n    'EAGLE' : 0,\\n    'FERRARI' : 0.587,\\n    'FIAT' : 0.024,\\n    'FISKER' : 0,\\n    'FORD' : 0.734,\\n    'GENESIS' : 0.575,\\n    'GEO' : 0,\\n    'GMC' : 0.502,\\n    'HONDA' : 0.621,\\n    'HUMMER' : 0,\\n    'HYUNDAI' : 0.64,\\n    'INFINITI' : 0.379,\\n    'ISUZU' : 0,\\n    'JAGUAR' : 0.125,\\n    'JEEP' : 0.527,\\n    'KARMA' : 0.444,\\n    'KIA' : 0.648,\\n    'LAMBORGHINI' : 0.413,\\n    'LAND ROVER' : 0.376,\\n    'LEXUS' : 0.553,\\n    'LINCOLN' : 0.571,\\n    'LOTUS' : 0,\\n    'MASERATI' : 0.488,\\n    'MAYBACH' : 0,\\n    'MAZDA' : 0,\\n    'MCLAREN' : 0.455,\\n    'MERCEDES-BENZ' : 0.543,\\n    'MERCURY' : 0,\\n    'MERKUR' : 0,\\n    'MINI' : 0.409,\\n    'MITSUBISHI' : 0.533,\\n    'NISSAN' : 0.609,\\n    'OLDSMOBILE' : 0,\\n    'PEUGEOT' : 0,\\n    'PININFARINA' : 0,\\n    'PLYMOUTH' : 0,\\n    'POLESTAR' : 0.412,\\n    'PONTIAC' : 0,\\n    'PORSCHE' : 0.529,\\n    'RAM' : 0.6,\\n    'RENAULT' : 0,\\n    'ROLLS-ROYCE' : 0.52,\\n    'SAAB' : 0,\\n    'SATURN' : 0,\\n    'SCION' : 0,\\n    'SMART' : 0,\\n    'SUBARU' : 0.624,\\n    'SUZUKI' : 0,\\n    'TESLA' : 0.796,\\n    'TOYOTA' : 0.637,\\n    'VOLKSWAGEN' : 0.563,\\n    'VOLVO' : 0.535,\\n    'WAGONEER' : 0\\n}\\n\\n# This is how a person's car is defined as Luxury \\nluxury_brands = ['ACURA', 'ALFA ROMEO', 'ASTON MARTIN', 'AUDI', 'BENTLEY', 'BUICK', 'BMW', 'CADILLAC', 'FERRARI', 'FIAT', 'FISKER', 'GENESIS', 'HUMMER', 'INFINITI', 'JAGUAR', 'KARMA', 'LAMBORGHINI', 'LAND ROVER', 'LEXUS', 'LINCOLN', 'LOTUS', 'MASERATI', 'MAYBACH', 'MCLAREN', 'MERCEDES-BENZ', 'MINI', 'PININFARINA', 'POLESTAR', 'PORSCHE', 'ROLLS-ROYCE', 'SAAB', 'TESLA', 'VOLVO']\\n\\n# Define spacious vehicle types\\nspacious_vehicle_types = {'SUV', 'MID_SIZE_SUV', 'FULL_SIZE_SUV', 'MINIVAN'}\\n\\n# Define luxury vehicle types\\nluxury_vehicle_types = {'SEDAN', 'SPORTS_CAR', 'ELECTRIC_VEHICLE', 'FULL_SIZE_SUV'}\\n\\n\\n# Assuming a mapping of IncomeKey from A (lowest) to higher (more likely to afford luxury)\\nincome_key_mapping = {key: index + 1 for index, key in enumerate([\\\"A\\\", \\\"B\\\", \\\"C\\\", \\\"D\\\", \\\"E\\\", \\\"F\\\", \\\"G\\\", \\\"H\\\", \\\"I\\\", \\\"J\\\", \\\"K\\\", \\\"L\\\", \\\"M\\\", \\\"N\\\", \\\"O\\\", \\\"P\\\", \\\"Q\\\", \\\"R\\\", \\\"U\\\"])}\\n\\n# Function to assign a random vehicle\\ndef assign_random_vehicle(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\\n    weights = []\\n    for _, row in vehicle_list_df.iterrows():\\n        weight = 1.0\\n\\n        # Adjust weight based on loyalty score\\n        if row['MAKE'] == owner_make:\\n            weight += owner_loyalty_score\\n\\n        # Adjust weight for luxury owners\\n        if is_luxury_owner and row['MAKE'] in luxury_brands:\\n            weight *= 2\\n\\n        # Adjust weight for owners with children preferring spacious vehicles\\n        if presence_of_children == 'Yes' and any(row[type_col] == 1 for type_col in spacious_vehicle_types):\\n            weight *= 1.5\\n\\n        # Adjust weight based on income key (higher income, higher weight for luxury vehicles)\\n        if row['MAKE'] in luxury_brands and income_key >= 15:  # Assuming income keys 15 and above indicate higher income\\n            weight *= 1.5\\n\\n        weights.append(weight)\\n\\n    # Normalize the weights\\n    total_weight = sum(weights)\\n    normalized_weights = [w / total_weight for w in weights]\\n\\n    # Choose the top 3 vehicles based on the weights\\n    chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=normalized_weights)\\n    recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\\n    return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records')\\n# Function to assign the top 3 most likely vehicles\\n\\ndef perform_sanity_checks(recommended_vehicles, debug_info, vehicle_list_df, luxury_brands, owner_luxury):\\n    errors = []  # To store any errors found during sanity checks\\n\\n    # Check if the recommended vehicles' types match one of the types in the dataframe\\n    for rec in recommended_vehicles:\\n        make = rec['MAKE']\\n        model = rec['MODEL']\\n        has_valid_type = any(vehicle_list_df[(vehicle_list_df['MAKE'] == make) & (vehicle_list_df['MODEL'] == model)][col] == 1 for col in vehicle_list_df.columns if col.startswith('TYPE_'))\\n        if not has_valid_type:\\n            errors.append(f\\\"Inappropriate or undefined vehicle type for {make} {model}.\\\")\\n\\n    # If owner does not own a luxury brand, it's okay to recommend non-luxury brands\\n    if owner_luxury and not all(rec['MAKE'] in luxury_brands for rec in recommended_vehicles):\\n        errors.append(\\\"Non-luxury brands are being recommended to a luxury brand owner.\\\")\\n\\n    # Check if the weights are correctly adjusted and normalized\\n    total_weight = sum(item['Final Weight'] for item in debug_info)\\n    expected_total_weight = len(debug_info)  # Should be equal to the number of rows iterated over\\n    if not np.isclose(total_weight, expected_total_weight, rtol=1e-03):\\n        errors.append(f\\\"Total weight mismatch. Expected ~{expected_total_weight}, got {total_weight}.\\\")\\n\\n    if errors:\\n        print(\\\"Sanity checks failed with the following errors:\\\")\\n        for error in errors:\\n            print(f\\\" - {error}\\\")\\n    else:\\n        print(\\\"Sanity checks passed.\\\")\\n\\n\\n\\\"\\\"\\\"def assign_top_vehicles(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\\n    weights = []\\n    debug_info = []  # To store debug information\\n\\n    print(\\\"\\\\n### Debugging Weights Calculation Start ###\\\")  # Start of debugging block\\n\\n    for index, row in vehicle_list_df.iterrows():\\n        weight = 1.0\\n        debug_details = {'Index': index, 'Make': row['MAKE'], 'Model': row['MODEL'], 'Initial Weight': weight}\\n\\n        print(f\\\"Initial weight for {row['MAKE']} {row['MODEL']}: {weight}\\\")  # Initial weight\\n\\n        # Adjust weight based on loyalty score\\n        if row['MAKE'] == owner_make:\\n            loyalty_bonus = owner_loyalty_score\\n            weight *= (1 + loyalty_bonus)  # Increase the likelihood for the same make\\n            debug_details['Loyalty Weight Adjustment'] = f\\\"+{loyalty_bonus}\\\"\\n\\n        # Adjust weight for luxury owners\\n        if is_luxury_owner and row['MAKE'] in luxury_brands:\\n            weight *= 2\\n            debug_details['Luxury Owner Weight Multiplier'] = 2\\n            print(\\\"Luxury owner: weight doubled\\\")  # Luxury owner adjustment\\n\\n        # Adjust weight for owners with children preferring spacious vehicles\\n        if presence_of_children == 'Yes' and any(row[type_col] == 1 for type_col in spacious_vehicle_types):\\n            weight *= 1.5\\n            debug_details['Children Weight Multiplier'] = 1.5\\n            print(\\\"Presence of children: weight *= 1.5\\\")  # Children presence adjustment\\n\\n        # Adjust weight based on income key\\n        if row['MAKE'] in luxury_brands and income_key >= 15:  # Assuming income keys 15 and above indicate higher income\\n            weight *= 1.5\\n            debug_details['Income Weight Multiplier'] = 1.5\\n            print(\\\"Higher income level: weight *= 1.5\\\")  # Income level adjustment\\n\\n        weights.append(weight)\\n        debug_details['Final Weight'] = weight\\n        debug_info.append(debug_details)\\n        print(f\\\"Final weight for {row['MAKE']} {row['MODEL']}: {weight}\\\")  # Final weight\\n\\n    print(\\\"Total weight before normalization:\\\", sum(weights))  # Total weight before normalization\\n\\n    # Normalize the weights\\n    total_weight = sum(weights)\\n    normalized_weights = [w / total_weight for w in weights]\\n\\n    print(\\\"Normalized weights:\\\", normalized_weights)  # Normalized weights\\n\\n    # Choose the top 3 vehicles based on the weights\\n    chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=normalized_weights)\\n    recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\\n\\n    print(\\\"\\\\n### Debugging Weights Calculation End ###\\\")  # End of debugging block\\n\\n    # Debug print\\n    pprint(\\\"Vehicle Selection Debug Information:\\\")\\n    for info in debug_info:\\n        if info['Index'] in chosen_indices:\\n            pprint(info)\\n    \\n    # Return both recommended vehicles and debug information\\n    return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records'), debug_info\\n\\n\\\"\\\"\\\"\\ndef assign_top_vehicles(owner_make, owner_loyalty_score, is_luxury_owner, presence_of_children, income_key):\\n    # Initialize weights as 1 for all vehicles\\n    weights = np.ones(len(vehicle_list_df))\\n    \\n    # Adjust weight based on loyalty score\\n    loyalty_weight_mask = (vehicle_list_df['MAKE'] == owner_make)\\n    weights[loyalty_weight_mask] += owner_loyalty_score\\n    \\n    # Adjust weight for luxury owners\\n    if is_luxury_owner:\\n        luxury_mask = vehicle_list_df['MAKE'].isin(luxury_brands)\\n        weights[luxury_mask] *= 2\\n    \\n    # Adjust weight for owners with children preferring spacious vehicles\\n    if presence_of_children == 'Yes':\\n        for vehicle_type in spacious_vehicle_types:\\n            spacious_mask = (vehicle_list_df[vehicle_type] == 1)\\n            weights[spacious_mask] *= 1.5\\n    \\n    # Adjust weight based on income key\\n    if income_key >= 15:  # Assuming income keys 15 and above indicate higher income\\n        higher_income_luxury_mask = vehicle_list_df['MAKE'].isin(luxury_brands)\\n        weights[higher_income_luxury_mask] *= 1.5\\n    \\n    # Normalize the weights\\n    weights /= weights.sum()\\n    \\n    # Choose the top 3 vehicles based on the weights\\n    chosen_indices = np.random.choice(len(vehicle_list_df), size=3, replace=False, p=weights)\\n    recommended_vehicles = vehicle_list_df.iloc[chosen_indices]\\n    \\n    return recommended_vehicles[['MAKE', 'MODEL', 'VEHICLE_TYPES']].to_dict('records')\\n\\ndb_config = {\\n    'host': 'localhost',\\n    'user': 'root',\\n    'password': 'password1',\\n    'database': 'db'\\n}\\n\\ndef create_db_connection():\\n    try:\\n        conn = mysql.connector.connect(**db_config)\\n        print(\\\"Database connection established.\\\")\\n        return conn\\n    except mysql.connector.Error as err:\\n        print(f\\\"Error: {err}\\\")\\n        return None\\n# Function to insert recommendations into the database\\ndef insert_recommendations(conn, customer_id, recommendations):\\n    cursor = conn.cursor()\\n    for rec in recommendations:\\n        insert_query = (\\\"INSERT INTO vehicle_recommendations (customer_id, make, model, vehicle_types) \\\"\\n                        \\\"VALUES (%s, %s, %s, %s)\\\")\\n        cursor.execute(insert_query, (customer_id, rec['MAKE'], rec['MODEL'], rec['VEHICLE_TYPES']))\\n    conn.commit()\\n    cursor.close()\\n\\n# Function to fetch data and recommend vehicles\\ndef fetch_data_and_recommend(conn):\\n    cursor = conn.cursor(dictionary=True)\\n    query = \\\"SELECT id, PresenceOfChildren, AutoOwnerMake, IncomeKey FROM inventory_table where InventoryId = 50017786\\\"\\n    cursor.execute(query)\\n    results = cursor.fetchall()\\n    for record in results:\\n        owner_make = record['AutoOwnerMake'].upper()\\n        loyalty_score = loyalty_scores.get(owner_make, 0)\\n        is_luxury_owner = owner_make in luxury_brands\\n        presence_of_children = 'Yes' if record['PresenceOfChildren'] == 'Yes' else 'No'\\n        income_rank = income_key_mapping.get(record['IncomeKey'].upper(), 0)  # Default to 0 if not found\\n\\n        owner_luxury = owner_make in luxury_brands\\n        # top_vehicles, debug_info = assign_top_vehicles(owner_make, loyalty_score, owner_luxury, presence_of_children, income_rank)\\n        insert_recommendations(conn, record['id'], top_vehicles)\\n        perform_sanity_checks(top_vehicles, debug_info, vehicle_list_df, luxury_brands, owner_luxury)\\n\\n        pprint(f\\\"Profile: {record}\\\")\\n        for vehicle in top_vehicles:\\n            pprint(f\\\"Recommendation: {vehicle['MAKE']} {vehicle['MODEL']} ({vehicle['VEHICLE_TYPES']})\\\")\\n    \\n    cursor.close()\\n    \\n    \\nif __name__ == '__main__':\\n    conn = create_db_connection()\\n    if conn:\\n        fetch_data_and_recommend(conn)\\n        conn.close()\\n    else:\\n        print(\\\"Failed to establish database connection.\\\")\", \"stderr\": \"\", \"artifacts\": []}\u001b[0m"
     ]
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"read the python code that i have uploaded.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
